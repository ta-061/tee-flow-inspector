#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
脆弱性解析結果のパース（改善版）
FINDINGS/END_FINDINGSの両方に対応し、堅牢なJSON解析を実装
プレースホルダー置換とバリデーション緩和を追加
"""

import re
import json
import hashlib
from typing import Dict, List, Tuple, Optional
from pathlib import Path
from .json_repair import JSONRepair


class VulnerabilityParser:
    def __init__(self, debug=False):
        self.debug = debug
        self.json_repair = JSONRepair(debug=debug)
        self.stats = {
            "total_parses": 0,
            "parse_failures": 0,
            "vulnerabilities_found": 0,
            "inline_findings_found": 0,
            "end_findings_found": 0,
            "findings_parse_attempts": 0,
            "findings_parse_successes": 0,
            "findings_parse_failures": 0,
            "placeholder_replacements": 0,
            "line_coercions": 0,
            "fallback_extractions": 0
        }
        # 動的ルールの初期値（既存の3種をデフォルトに）
        self.known_rules = ["unencrypted_output", "weak_input_validation", "shared_memory_overwrite"]

    def validate_taint_response_format(self, response: str) -> Tuple[bool, str]:
        """
        テイント解析応答の形式を検証（厳密版）
        Returns: (is_valid, error_message)
        """
        lines = [l.strip() for l in (response or "").splitlines() if l.strip()]
        if not lines:
            return False, "Empty response"

        # --- 1st line: strict JSON object check ---
        first_line_data = self.json_repair.safe_json_loads(lines[0], None)
        if not isinstance(first_line_data, dict):
            return False, "First line is not a valid JSON object"

        required_keys = {"function", "propagation", "sanitizers", "sinks", "evidence", "rule_matches"}
        missing = required_keys - set(first_line_data.keys())
        if missing:
            return False, f"Missing required keys: {sorted(missing)}"

        # type checks
        for k in ("propagation", "sanitizers", "sinks", "evidence"):
            if not isinstance(first_line_data.get(k), list):
                return False, f"'{k}' must be an array"

        rm = first_line_data.get("rule_matches")
        if not isinstance(rm, dict):
            return False, "'rule_matches' must be an object with 'rule_id' and 'others'"
        if not isinstance(rm.get("rule_id"), list) or not isinstance(rm.get("others"), list):
            return False, "'rule_matches.rule_id' and 'rule_matches.others' must be arrays"

        # --- 2nd line: FINDINGS= {...} must exist ---
        if len(lines) < 2:
            return False, "Missing second line: FINDINGS={...}"

        if not re.match(r'^FINDINGS\s*=', lines[1]):
            return False, "Second line must begin with 'FINDINGS='"

        # Try parsing FINDINGS using JSONRepair patterns
        patterns = [
            r'^FINDINGS\s*=\s*(\{"items"\s*:\s*\[[\s\S]*?\]\})',
            r'^FINDINGS\s*=\s*(\{[\s\S]*"items"[\s\S]*\})'
        ]
        matches = self.json_repair.extract_json_patterns("\n".join(lines[1:]), patterns)
        obj = self.json_repair.parse_best_match(matches, {"items": []})
        if "items" not in obj:
            return False, "FINDINGS does not contain an 'items' array"

        return True, ""

    def set_known_rules(self, rules_json: dict):
        """CodeQLルールから既知のrule_idリストを設定"""
        ids = []
        for k in ("detection_rules", "rules"):
            for rule in (rules_json.get(k) or []):
                rid = rule.get("rule_id")
                if rid:
                    ids.append(rid)
        if ids:
            self.known_rules = sorted(set(ids))
    
    def _coerce_placeholder_file(self, path: Optional[str], default_file: Optional[str]) -> Optional[str]:
        """
        プレースホルダーを既定ファイルに置換する
        
        Args:
            path: 検証対象のファイルパス
            default_file: デフォルトのファイルパス
        
        Returns:
            置換後のファイルパス
        """
        if not path:
            return default_file
        
        path_str = str(path).strip()
        path_lower = path_str.lower()
        
        # よく見られるプレースホルダーのパターン
        placeholders = {
            "unknown", "<path>", "<path|'unknown'>", "n/a", "na", 
            "???", "undefined", "null", "none", "<file>", "<unknown>"
        }
        
        # プレースホルダーを検出
        is_placeholder = (
            path_lower in placeholders or
            any(p in path_lower for p in ["unknown", "<path", "<file"]) or
            path_str.startswith("<") and path_str.endswith(">")
        )
        
        if is_placeholder:
            if self.debug:
                print(f"[DEBUG] Replacing placeholder '{path}' with '{default_file}'")
            self.stats["placeholder_replacements"] += 1
            return default_file
        
        return path
    
    def parse_vuln_response(self, resp: str) -> Tuple[bool, dict]:
        """
        脆弱性判定レスポンスをパース
        
        Returns:
            (is_vulnerable, metadata)
        """
        self.stats["total_parses"] += 1
        
        # 複数の形式に対応
        # 1. マークダウンコードブロック内のJSON
        json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', resp, re.DOTALL)
        if json_match:
            data = self.json_repair.safe_json_loads(
                json_match.group(1), 
                {"vulnerability_found": "no"}
            )
            flag = str(data.get("vulnerability_found", "")).lower()
            if flag == "yes":
                self.stats["vulnerabilities_found"] += 1
            return flag == "yes", data
        
        # 2. 最初の行に直接JSON
        lines = resp.strip().splitlines()
        if lines:
            first_line = lines[0].strip()
            data = self.json_repair.safe_json_loads(
                first_line,
                {"vulnerability_found": "no"}
            )
            flag = str(data.get("vulnerability_found", "")).lower()
            if flag == "yes":
                self.stats["vulnerabilities_found"] += 1
            return flag == "yes", data
        
        # 3. テキスト内のどこかにJSON風の文字列
        json_pattern = re.search(r'{\s*"vulnerability_found"\s*:\s*"(yes|no)"\s*}', resp)
        if json_pattern:
            data = self.json_repair.safe_json_loads(
                json_pattern.group(0),
                {"vulnerability_found": "no"}
            )
            flag = str(data.get("vulnerability_found", "")).lower()
            if flag == "yes":
                self.stats["vulnerabilities_found"] += 1
            return flag == "yes", data
        
        # パースに失敗
        self.stats["parse_failures"] += 1
        return False, {}
    
    def parse_first_json_line(self, resp: str) -> Optional[dict]:
        """応答の最初のJSON行をパース"""
        lines = [l.strip() for l in (resp or "").splitlines() if l.strip()]
        if not lines:
            return None
        
        # 最初の行を試す
        result = self.json_repair.safe_json_loads(lines[0], None)
        if result:
            return result
        
        # ```json ブロック内にも対応
        m = re.search(r'```(?:json)?\s*({.*?})\s*```', resp, re.DOTALL)
        if m:
            return self.json_repair.safe_json_loads(m.group(1), None)
        
        return None
    
    def make_finding_id(self, file_path: str, function: str, primary_rule_id: str, line: int, bucket: int = 2) -> str:
        """
        脆弱性発見項目のユニークIDを生成
        """
        key = f"{file_path}:{function}:{primary_rule_id}:{line // max(1, bucket)}"
        return hashlib.sha1(key.encode()).hexdigest()[:12]
    
    def _standardize_finding(
        self, 
        item: dict, 
        func_name: str, 
        phase: str = "middle",
        default_file: Optional[str] = None
    ) -> dict:
        """
        発見項目を標準化し、必須フィールドを補完
        """
        # phaseの補完と正規化
        if "phase" not in item:
            item["phase"] = phase
        else:
            current_phase = item["phase"].lower()
            if current_phase == "start":
                item["phase"] = "middle"
                if self.debug:
                    print(f"[DEBUG] Phase 'start' normalized to 'middle' for finding in {func_name}")
            elif current_phase not in ["middle", "end"]:
                if self.debug:
                    print(f"[DEBUG] Unexpected phase value '{current_phase}' in finding, using '{phase}'")
                item["phase"] = phase
        
        # functionの補完
        if "function" not in item or not item["function"]:
            item["function"] = func_name
        
        # sink_functionの補完
        if "sink_function" not in item:
            item["sink_function"] = "unknown"
        
        # rule_matchesの補完
        if "rule_matches" not in item:
            if "rule" in item and item["rule"]:
                rule = item["rule"]
                rule_ids = []
                known_rules = self.known_rules
                # パイプ区切りも対応
                if "|" in rule:
                    for pr in (x.strip() for x in rule.split("|")):
                        if pr in known_rules:
                            rule_ids.append(pr)
                elif rule in known_rules:
                    rule_ids.append(rule)

                if rule_ids:
                    item["rule_matches"] = {"rule_id": sorted(set(rule_ids)), "others": []}
                else:
                    item["rule_matches"] = {"rule_id": [], "others": [rule] if rule else []}
            else:
                item["rule_matches"] = {"rule_id": [], "others": []}
        else:
            # 既存のrule_matchesを正規化
            known_rules = self.known_rules
            rm = item["rule_matches"] if isinstance(item["rule_matches"], dict) else {}
            rids = [r for r in (rm.get("rule_id") or []) if r in known_rules]
            others = (rm.get("others") or []) + [r for r in (rm.get("rule_id") or []) if r not in known_rules]
            item["rule_matches"] = {
                "rule_id": sorted(set(rids)),
                "others": sorted(set(others))
            }
        
        # fileの補完（プレースホルダー置換を含む）
        original_file = item.get("file")
        item["file"] = self._coerce_placeholder_file(original_file, default_file)
        if original_file != item["file"] and self.debug:
            print(f"[DEBUG] Replaced file placeholder '{original_file}' with '{item['file']}'")
        
        # lineの補完
        if "line" not in item:
            item["line"] = 1
        else:
            try:
                item["line"] = int(item.get("line", 1))
            except Exception:
                item["line"] = 1
            item["line"] = max(1, item["line"])
        
        # primary_rule_idの取得
        primary_rule_id = "none"
        if item["rule_matches"]["rule_id"]:
            primary_rule_id = item["rule_matches"]["rule_id"][0]
        elif item.get("rule"):
            rule = item["rule"]
            if "|" in rule:
                primary_rule_id = rule.split("|")[0].strip()
            else:
                primary_rule_id = rule
        
        # IDの生成
        item["id"] = self.make_finding_id(
            file_path=item.get("file", "unknown"),
            function=item["function"],
            primary_rule_id=primary_rule_id,
            line=item["line"]
        )
        
        return item

    def extract_inline_findings(
        self, 
        resp: str, 
        func_name: str, 
        chain: List[str], 
        vd: dict, 
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        応答からインライン脆弱性情報を抽出（FINDINGS形式）
        """
        findings = []
        self.stats["findings_parse_attempts"] += 1
        
        default_file = vd.get('current_file', vd.get('file'))
        
        if self.debug:
            print(f"[DEBUG] Attempting to extract FINDINGS from response (len={len(resp)})")
        
        # 厳密→緩いの順でパターンを定義
        patterns = [
            r'FINDINGS\s*=\s*(\{"items"\s*:\s*\[[^\]]*\]\})',
            r'FINDINGS\s*=\s*(\{[^}]*"items"[^}]*\})',
            r'FINDINGS\s*=\s*(\{.*?\})\s*(?:\n|$)',
            r'^\s*FINDINGS\s*=\s*(.+?)$',
            r'FINDINGS\s*=\s*(\{.*?\})',
        ]
        
        matches = self.json_repair.extract_json_patterns(resp or "", patterns)
        
        if not matches and "FINDINGS" in (resp or ""):
            print(f"[WARN] 'FINDINGS' found in response but no patterns matched")
            if self.debug:
                findings_pos = resp.find("FINDINGS")
                snippet = resp[findings_pos:findings_pos+200] if findings_pos >= 0 else ""
                print(f"[DEBUG] Response snippet: {repr(snippet)}")
            self.stats["findings_parse_failures"] += 1
            return findings
        
        obj = self.json_repair.parse_best_match(matches, {"items": []})
        items = obj.get("items", [])
        
        if not items:
            if self.debug:
                print(f"[DEBUG] Successfully parsed FINDINGS with 0 items (no vulnerabilities found)")
            self.stats["findings_parse_successes"] += 1
            return findings
        
        if self.debug:
            print(f"[DEBUG] Successfully parsed FINDINGS with {len(items)} items")
        
        self.stats["findings_parse_successes"] += 1
        
        for item in items:
            standardized = self._standardize_finding(
                item.copy(),
                func_name=func_name,
                phase="middle",
                default_file=default_file
            )
            
            line_num = standardized["line"]
            file_path = standardized["file"]
            
            # 行番号検証（緩和版 - 警告のみ）
            if not self._validate_line_number(file_path, line_num, project_root):
                print(f"[WARN] Line number {line_num} may be invalid for {file_path}")
                # フォールバックとして vd の行番号を使用
                if vd.get("line"):
                    standardized["line"] = vd["line"]
                    standardized.setdefault("meta", {})["line_coerced"] = True
                    self.stats["line_coercions"] += 1
            
            findings.append({
                "id": standardized["id"],
                "chain": chain,
                "function": standardized["function"],
                "sink_function": standardized["sink_function"],
                "category": standardized.get("rule"),
                "file": file_path,
                "line": standardized["line"],
                "message": standardized.get("why") or "",
                "phase": standardized["phase"],
                "rule_matches": standardized["rule_matches"],
                "rag_refs": item.get("rag_refs", []), 
                "code_excerpt": item.get("code_excerpt"),
                "source": "FINDINGS_JSON",
                "meta": standardized.get("meta", {})
            })
            
            if self.debug:
                print(f"[DEBUG] Added finding: {standardized['function']} at {file_path}:{standardized['line']}")
        
        if findings:
            self.stats["inline_findings_found"] += len(findings)
            if self.debug:
                print(f"[DEBUG] Total findings extracted: {len(findings)}")
        
        return findings
    
    def extract_end_findings(
        self, 
        resp: str, 
        func_name: str, 
        chain: List[str], 
        vd: dict,
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        END_FINDINGS抽出（改善版）
        - プレースホルダーの自動置換
        - FINDINGSへのフォールバック
        - 行番号検証の緩和
        """
        findings = []
        default_file = vd.get('current_file', vd.get('file'))
        
        if self.debug:
            print(f"[DEBUG] Attempting to extract END_FINDINGS from response")

        # パターンマッチング
        patterns = [
            r'END_FINDINGS\s*=\s*(\{"items"\s*:\s*\[[^\]]*\]\})',
            r'END_FINDINGS\s*=\s*(\{[^}]*"items"[^}]*\})',
            r'END_FINDINGS\s*=\s*(\{.*?\})\s*(?:\n|$)',
            r'^\s*END_FINDINGS\s*=\s*(\{.*\})\s*$',
            r'^\s*END_FINDINGS\s*:\s*(\{.*\})\s*$',
            r'^\s*END_FINDINGS\s*->\s*(\{.*\})\s*$'
        ]
        
        matches = self.json_repair.extract_json_patterns(resp or "", patterns)
        
        # 【改善点1】END_FINDINGSが見つからない場合、FINDINGSにフォールバック
        if not matches:
            if "END_FINDINGS" in (resp or ""):
                print(f"[WARN] 'END_FINDINGS' found but no patterns matched")
            
            # FINDINGSを探す
            if "FINDINGS" in (resp or ""):
                print(f"[INFO] Falling back to FINDINGS extraction")
                self.stats["fallback_extractions"] += 1
                return self.extract_inline_findings(resp, func_name, chain, vd, project_root)
            
            return findings

        obj = self.json_repair.parse_best_match(matches, {"items": []})
        items = obj.get("items", [])
        
        if self.debug:
            print(f"[DEBUG] Successfully parsed END_FINDINGS with {len(items)} items")
        
        for item in items:
            std = self._standardize_finding(
                item.copy(), 
                func_name=func_name, 
                phase="end", 
                default_file=default_file
            )
            
            # 【改善点2】プレースホルダーの強制置換（_standardize_finding内で実行済み）
            
            # 【改善点3】行番号検証を緩和（警告のみ、棄却しない）
            if not self._validate_line_number(std.get("file"), std.get("line"), project_root):
                original_line = std.get("line")
                # vdの行番号をフォールバック
                std["line"] = vd.get("line", 1)
                print(f"[WARN] Invalid line {original_line} for {std.get('file')}, using line {std['line']}")
                std.setdefault("meta", {})["line_coerced"] = True
                self.stats["line_coercions"] += 1

            # findingを追加（棄却しない）
            findings.append({
                "id": std["id"],
                "chain": chain,
                "function": std["function"],
                "sink_function": std["sink_function"],
                "category": std.get("rule"),
                "file": std.get("file"),
                "line": std.get("line"),
                "message": item.get("why") or std.get("why") or "",
                "phase": std["phase"],
                "rule_matches": std["rule_matches"],
                "rag_refs": item.get("rag_refs", []),
                "code_excerpt": item.get("code_excerpt"),
                "source": "END_FINDINGS",
                "meta": std.get("meta", {})
            })

        if findings:
            self.stats["end_findings_found"] += len(findings)
            print(f"[INFO] Extracted {len(findings)} END_FINDINGS")

        return findings

    def extract_all_findings(
        self,
        resp: str,
        func_name: str,
        chain: List[str],
        vd: dict,
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        応答からFINDINGSとEND_FINDINGSの両方を抽出
        """
        all_findings = []
        
        if self.debug:
            print(f"\n[DEBUG] === Extracting findings for function: {func_name} ===")
        
        # FINDINGS（中間）を抽出
        inline_findings = self.extract_inline_findings(
            resp, func_name, chain, vd, project_root
        )
        all_findings.extend(inline_findings)
        
        # END_FINDINGS（最終）を抽出
        end_findings = self.extract_end_findings(
            resp, func_name, chain, vd, project_root
        )
        all_findings.extend(end_findings)
        
        if self.debug:
            print(f"[DEBUG] Total findings extracted: {len(all_findings)} "
                  f"(inline: {len(inline_findings)}, end: {len(end_findings)})")
        
        return all_findings
    
    def extract_all_findings_flexible(
        self, 
        resp: str, 
        func_name: str, 
        chain: List[str],
        vd: dict, 
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        すべての種類のFINDINGSを柔軟に抽出する
        重複を避けながら、複数のパターンを試行
        """
        all_findings = []
        seen_ids = set()
        
        # 1. END_FINDINGSを試す
        end_findings = self.extract_end_findings(resp, func_name, chain, vd, project_root)
        for f in end_findings:
            if f["id"] not in seen_ids:
                all_findings.append(f)
                seen_ids.add(f["id"])
        
        # 2. 通常のFINDINGSを試す（END_FINDINGSと重複しないもののみ）
        inline_findings = self.extract_inline_findings(resp, func_name, chain, vd, project_root)
        for f in inline_findings:
            if f["id"] not in seen_ids:
                all_findings.append(f)
                seen_ids.add(f["id"])
        
        # 3. その他のパターン（VULNERABILITY_FINDINGS等）も探す
        other_patterns = [
            (r'VULNERABILITY_FINDINGS\s*=\s*(\{.*?\})', "VULNERABILITY_FINDINGS"),
            (r'FINAL_FINDINGS\s*=\s*(\{.*?\})', "FINAL_FINDINGS"),
            (r'SINK_FINDINGS\s*=\s*(\{.*?\})', "SINK_FINDINGS")
        ]
        
        for pattern, source_name in other_patterns:
            matches = self.json_repair.extract_json_patterns(resp, [pattern])
            for _, json_str in matches:
                obj = self.json_repair.safe_json_loads(json_str, {"items": []})
                for item in obj.get("items", []):
                    std = self._standardize_finding(
                        item.copy(), func_name, "end", vd.get('file')
                    )
                    if std["id"] not in seen_ids:
                        finding = {
                            "id": std["id"],
                            "chain": chain,
                            "function": std["function"],
                            "sink_function": std["sink_function"],
                            "category": std.get("rule"),
                            "file": std.get("file"),
                            "line": std.get("line"),
                            "message": item.get("why") or "",
                            "phase": std["phase"],
                            "rule_matches": std["rule_matches"],
                            "source": source_name,
                            "meta": std.get("meta", {})
                        }
                        all_findings.append(finding)
                        seen_ids.add(std["id"])
        
        if all_findings:
            unique_inline = len([f for f in all_findings if f["source"] == "FINDINGS_JSON"])
            unique_end = len([f for f in all_findings if f["source"] == "END_FINDINGS"])
            unique_other = len(all_findings) - unique_inline - unique_end
            
            print(f"[INFO] Flexible extraction found {len(all_findings)} findings "
                  f"(FINDINGS: {unique_inline}, END: {unique_end}, OTHER: {unique_other})")
        
        return all_findings
    
    def extract_taint_state(self, response: str) -> dict:
        """関数解析レスポンスからテイント状態を抽出"""
        try:
            first_line = response.strip().split('\n')[0]
            data = self.json_repair.safe_json_loads(first_line, {})
            return {
                "propagated_values": data.get("propagation", []),
                "applied_sanitizers": data.get("sanitizers", []),
                "reached_sinks": data.get("sinks", [])
            }
        except:
            return {}
    
    def extract_security_observations(self, response: str) -> List[dict]:
        """セキュリティ関連の観察事項を抽出"""
        observations = []
        
        # FINDINGSとEND_FINDINGSから抽出
        patterns = [
            r'FINDINGS\s*=\s*(\{.*?\})',
            r'END_FINDINGS\s*=\s*(\{.*?\})'
        ]
        
        for pattern in patterns:
            matches = self.json_repair.extract_json_patterns(response, [pattern])
            for _, json_str in matches:
                obj = self.json_repair.safe_json_loads(json_str, {"items": []})
                for item in obj.get("items", []):
                    observations.append({
                        "type": item.get("rule"),
                        "observation": item.get("why"),
                        "location": f"{item.get('file')}:{item.get('line')}"
                    })
        
        return observations
    
    def extract_risk_indicators(self, response: str) -> List[str]:
        """リスク指標を抽出"""
        risk_indicators = []
        
        # 最初の行からルールマッチを抽出
        try:
            first_line = response.strip().split('\n')[0]
            data = self.json_repair.safe_json_loads(first_line, {})
            rm = data.get("rule_matches", {})
            if isinstance(rm, dict):
                for rid in rm.get("rule_id", []) or []:
                    risk_indicators.append(f"Matched rule_id: {rid}")
                for tag in rm.get("others", []) or []:
                    risk_indicators.append(f"Tagged: {tag}")
            elif isinstance(rm, list):  # 後方互換
                risk_indicators.extend([f"Matched rule: {rule}" for rule in rm])
        except:
            pass
        
        # テキストから危険なパターンを検出
        dangerous_patterns = [
            (r"no\s+bounds?\s+check", "No bounds checking detected"),
            (r"no\s+validation", "No validation detected"),
            (r"untrusted\s+input", "Untrusted input detected"),
            (r"without\s+sanitization", "Missing sanitization"),
            (r"buffer\s+overflow", "Potential buffer overflow"),
            (r"memory\s+corruption", "Potential memory corruption"),
            (r"injection", "Potential injection vulnerability")
        ]
        
        for pattern, indicator in dangerous_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                risk_indicators.append(indicator)
        
        return list(set(risk_indicators))
    
    def parse_detailed_vuln_response(self, resp: str) -> dict:
        """LLMの脆弱性判定レスポンスから詳細情報を抽出"""
        lines = resp.strip().split('\n')
        
        # 1行目の判定結果
        vuln_decision = {}
        if lines:
            vuln_decision = self.json_repair.safe_json_loads(lines[0], {})
        
        # 2行目以降の詳細分析
        details = {}
        if len(lines) > 1:
            remaining_text = '\n'.join(lines[1:])
            
            # 複数のJSONブロックパターンに対応
            json_patterns = [
                r'\{[\s\S]*"vulnerability_type"[\s\S]*\}',
                r'\{[\s\S]*"severity"[\s\S]*\}',
                r'\{[\s\S]*\}'
            ]
            
            matches = self.json_repair.extract_json_patterns(remaining_text, json_patterns)
            if matches:
                _, json_str = matches[0]
                details = self.json_repair.safe_json_loads(json_str, {})
            
            # JSONが見つからない場合は構造化解析
            if not details:
                details = self._parse_structured_explanation(remaining_text)
        
        return {
            "decision": vuln_decision,
            "details": details,
            "full_response": resp
        }
    
    def _parse_structured_explanation(self, text: str) -> dict:
        """構造化されたテキスト説明から情報を抽出"""
        result = {
            "vulnerability_type": "Unknown",
            "severity": "Unknown",
            "description": text
        }
        
        # CWE番号の抽出
        cwe_match = re.search(r'CWE-(\d+)', text)
        if cwe_match:
            result["vulnerability_type"] = f"CWE-{cwe_match.group(1)}"
        
        # 重要度の抽出
        severity_match = re.search(r'(critical|high|medium|low)\s+severity', text, re.IGNORECASE)
        if severity_match:
            result["severity"] = severity_match.group(1).lower()
        
        # 攻撃シナリオの抽出
        if "attack" in text.lower() or "exploit" in text.lower():
            attack_section = re.search(r'(attack|exploit)[^.]*\.([^.]*\.){0,3}', text, re.IGNORECASE)
            if attack_section:
                result["attack_scenario"] = attack_section.group(0)
        
        return result
    
    def _validate_line_number(self, file_path: str, line_num: int, project_root: Optional[Path] = None) -> bool:
        """行番号が有効かチェック（緩和版）"""
        if line_num <= 0:
            return False
        
        # ファイルが存在する場合のみ厳密にチェック
        try:
            if project_root and not Path(file_path).is_absolute():
                file_path = project_root / file_path
            
            if Path(file_path).exists():
                with open(file_path, 'r') as f:
                    total_lines = sum(1 for _ in f)
                    return 1 <= line_num <= total_lines
        except:
            pass
        
        # ファイルが見つからない場合は、妥当な範囲内ならOKとする
        return 1 <= line_num <= 100000
    
    def get_stats(self) -> dict:
        """統計情報を取得"""
        combined_stats = self.stats.copy()
        combined_stats["json_repair"] = self.json_repair.get_stats()
        return combined_stats
    
    def set_debug(self, debug: bool):
        """デバッグモードの設定"""
        self.debug = debug
        self.json_repair.debug = debug