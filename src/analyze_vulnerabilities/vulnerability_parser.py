#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
脆弱性解析結果のパース（拡張版）
FINDINGS/END_FINDINGSの両方に対応し、必須フィールド補完とID生成を実装
"""

import re
import json
import hashlib
from typing import Dict, List, Tuple, Optional
from pathlib import Path

class VulnerabilityParser:
    """
    LLMの応答から脆弱性情報を抽出・パースするクラス
    """
    
    def __init__(self):
        self.stats = {
            "total_parses": 0,
            "parse_failures": 0,
            "vulnerabilities_found": 0,
            "inline_findings_found": 0,
            "end_findings_found": 0
        }
    
    def parse_vuln_response(self, resp: str) -> Tuple[bool, dict]:
        """
        脆弱性判定レスポンスをパース
        
        Returns:
            (is_vulnerable, metadata)
        """
        self.stats["total_parses"] += 1
        
        # 複数の形式に対応
        # 1. マークダウンコードブロック内のJSON
        json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', resp, re.DOTALL)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                flag = str(data.get("vulnerability_found", "")).lower()
                if flag == "yes":
                    self.stats["vulnerabilities_found"] += 1
                return flag == "yes", data
            except json.JSONDecodeError:
                pass
        
        # 2. 最初の行に直接JSON
        lines = resp.strip().splitlines()
        if lines:
            first_line = lines[0].strip()
            try:
                data = json.loads(first_line)
                flag = str(data.get("vulnerability_found", "")).lower()
                if flag == "yes":
                    self.stats["vulnerabilities_found"] += 1
                return flag == "yes", data
            except json.JSONDecodeError:
                pass
        
        # 3. テキスト内のどこかにJSON風の文字列
        json_pattern = re.search(r'{\s*"vulnerability_found"\s*:\s*"(yes|no)"\s*}', resp)
        if json_pattern:
            try:
                data = json.loads(json_pattern.group(0))
                flag = str(data.get("vulnerability_found", "")).lower()
                if flag == "yes":
                    self.stats["vulnerabilities_found"] += 1
                return flag == "yes", data
            except json.JSONDecodeError:
                pass
        
        # パースに失敗
        self.stats["parse_failures"] += 1
        return False, {}
    
    def parse_first_json_line(self, resp: str) -> Optional[dict]:
        """応答の最初のJSON行をパース"""
        lines = [l.strip() for l in (resp or "").splitlines() if l.strip()]
        if not lines:
            return None
        
        try:
            return json.loads(lines[0])
        except json.JSONDecodeError:
            # ```json ブロック内にも対応
            m = re.search(r'```(?:json)?\s*({.*?})\s*```', resp, re.DOTALL)
            if m:
                try:
                    return json.loads(m.group(1))
                except json.JSONDecodeError:
                    return None
        return None
    
    def make_finding_id(self, file_path: str, function: str, primary_rule_id: str, line: int, bucket: int = 2) -> str:
        """
        脆弱性発見項目のユニークIDを生成
        
        Args:
            file_path: ファイルパス
            function: 関数名
            primary_rule_id: 主要ルールID
            line: 行番号
            bucket: 行番号のバケットサイズ（近い行をグループ化）
        
        Returns:
            12文字のハッシュID
        """
        key = f"{file_path}:{function}:{primary_rule_id}:{line // max(1, bucket)}"
        return hashlib.sha1(key.encode()).hexdigest()[:12]
    
    def _standardize_finding(
        self, 
        item: dict, 
        func_name: str, 
        phase: str = "middle",
        default_file: Optional[str] = None
    ) -> dict:
        """
        発見項目を標準化し、必須フィールドを補完
        
        Args:
            item: 元の発見項目
            func_name: 現在の関数名
            phase: 解析フェーズ（"middle" or "end"）
            default_file: デフォルトのファイルパス
        
        Returns:
            標準化された発見項目
        """
        # phaseの補完
        if "phase" not in item:
            item["phase"] = phase
        
        # functionの補完
        if "function" not in item or not item["function"]:
            item["function"] = func_name
        
        # sink_functionの補完
        if "sink_function" not in item:
            item["sink_function"] = "unknown"
        
        # rule_matchesの補完
        if "rule_matches" not in item:
            # ruleフィールドから推測
            if "rule" in item and item["rule"]:
                item["rule_matches"] = {
                    "rule_id": [item["rule"]],
                    "others": []
                }
            else:
                item["rule_matches"] = {
                    "rule_id": [],
                    "others": []
                }
        
        # fileの補完
        if (not item.get("file") or item.get("file") == "unknown") and default_file:
            item["file"] = default_file
        
        # lineの補完（0の場合は1にする）
        if "line" not in item:
            item["line"] = 1
        else:
            item["line"] = max(1, int(item.get("line", 1)))
        
        # primary_rule_idの取得
        primary_rule_id = "none"
        if item["rule_matches"]["rule_id"]:
            primary_rule_id = item["rule_matches"]["rule_id"][0]
        elif item.get("rule"):
            primary_rule_id = item["rule"]
        
        # IDの生成
        item["id"] = self.make_finding_id(
            file_path=item.get("file", "unknown"),
            function=item["function"],
            primary_rule_id=primary_rule_id,
            line=item["line"]
        )
        
        return item
    
    def extract_inline_findings(
        self, 
        resp: str, 
        func_name: str, 
        chain: List[str], 
        vd: dict, 
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        応答からインライン脆弱性情報を抽出（FINDINGS形式）
        """
        findings = []
        
        # デフォルトファイルの優先順位：
        # 1. current_file（現在解析中の関数のファイル）
        # 2. file（シンク関数のファイル）
        default_file = vd.get('current_file', vd.get('file'))
        
        # FINDINGS=<json> 形式を抽出
        mjson = re.search(r'^\s*FINDINGS\s*=\s*(.+?)$', resp or "", re.MULTILINE)
        if not mjson:
            return findings
        
        try:
            json_str = mjson.group(1).strip()
            
            # JSONの終端を正しく検出
            brace_count = 0
            in_string = False
            escape_next = False
            json_end = 0
            
            for i, char in enumerate(json_str):
                if escape_next:
                    escape_next = False
                    continue
                
                if char == '\\':
                    escape_next = True
                    continue
                
                if char == '"' and not in_string:
                    in_string = True
                elif char == '"' and in_string:
                    in_string = False
                elif not in_string:
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
            
            if json_end > 0:
                clean_json = json_str[:json_end]
                
                if json_end < len(json_str):
                    extra_chars = json_str[json_end:].strip()
                    if extra_chars and extra_chars not in ['"', '}"', '}"}']:
                        print(f"[DEBUG] Extra characters after JSON: {repr(extra_chars)}")
                
                obj = json.loads(clean_json)
                
                for item in obj.get("items", []):
                    # 標準化処理
                    standardized = self._standardize_finding(
                        item.copy(),
                        func_name=func_name,
                        phase="middle",
                        default_file=default_file
                    )
                    
                    line_num = standardized["line"]
                    file_path = standardized["file"]
                    
                    if line_num == 0:
                        print(f"[WARN] No line number provided for {func_name}")
                        continue
                    
                    if file_path and not self._validate_line_number(file_path, line_num, project_root):
                        print(f"[WARN] Invalid line number {line_num} for {file_path}")
                        continue
                    
                    findings.append({
                        "id": standardized["id"],
                        "chain": chain,
                        "function": standardized["function"],
                        "sink_function": standardized["sink_function"],
                        "category": standardized.get("rule"),
                        "file": file_path,
                        "line": line_num,
                        "message": standardized.get("why") or "",
                        "phase": standardized["phase"],
                        "rule_matches": standardized["rule_matches"],
                        "source": "FINDINGS_JSON"
                    })
            else:
                print(f"[WARN] Invalid JSON structure in FINDINGS: braces not balanced")
                print(f"[DEBUG] Raw JSON string: {repr(json_str[:100])}...")
                
        except json.JSONDecodeError as e:
            print(f"[WARN] Failed to parse FINDINGS JSON: {e}")
            if mjson:
                print(f"[DEBUG] Raw JSON string: {repr(mjson.group(1)[:100])}...")
        except Exception as e:
            print(f"[WARN] Unexpected error parsing FINDINGS: {e}")
        
        if findings:
            self.stats["inline_findings_found"] += len(findings)
        
        return findings
    
    def extract_end_findings(
        self,
        resp: str,
        func_name: str,
        chain: List[str],
        vd: dict,
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        応答から最終脆弱性情報を抽出（END_FINDINGS形式）
        """
        findings = []
        
        # デフォルトファイルの優先順位
        default_file = vd.get('current_file', vd.get('file'))
        
        # END_FINDINGS=<json> 形式を抽出
        mjson = re.search(r'^\s*END_FINDINGS\s*=\s*(.+?)$', resp or "", re.MULTILINE)
        if not mjson:
            return findings
        
        try:
            json_str = mjson.group(1).strip()
            
            # JSONの終端を正しく検出（extract_inline_findingsと同じロジック）
            brace_count = 0
            in_string = False
            escape_next = False
            json_end = 0
            
            for i, char in enumerate(json_str):
                if escape_next:
                    escape_next = False
                    continue
                
                if char == '\\':
                    escape_next = True
                    continue
                
                if char == '"' and not in_string:
                    in_string = True
                elif char == '"' and in_string:
                    in_string = False
                elif not in_string:
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break
            
            if json_end > 0:
                clean_json = json_str[:json_end]
                obj = json.loads(clean_json)
                
                for item in obj.get("items", []):
                    # 標準化処理
                    standardized = self._standardize_finding(
                        item.copy(),
                        func_name=func_name,
                        phase="end",  # END_FINDINGSなのでphaseは"end"
                        default_file=default_file
                    )
                    
                    line_num = standardized["line"]
                    file_path = standardized["file"]
                    
                    if line_num == 0:
                        print(f"[WARN] No line number provided for {func_name} in END_FINDINGS")
                        continue
                    
                    if file_path and not self._validate_line_number(file_path, line_num, project_root):
                        print(f"[WARN] Invalid line number {line_num} for {file_path} in END_FINDINGS")
                        continue
                    
                    findings.append({
                        "id": standardized["id"],
                        "chain": chain,
                        "function": standardized["function"],
                        "sink_function": standardized["sink_function"],
                        "category": standardized.get("rule"),
                        "file": file_path,
                        "line": line_num,
                        "message": standardized.get("why") or "",
                        "phase": standardized["phase"],
                        "rule_matches": standardized["rule_matches"],
                        "source": "END_FINDINGS_JSON"
                    })
            else:
                print(f"[WARN] Invalid JSON structure in END_FINDINGS: braces not balanced")
                
        except json.JSONDecodeError as e:
            print(f"[WARN] Failed to parse END_FINDINGS JSON: {e}")
        except Exception as e:
            print(f"[WARN] Unexpected error parsing END_FINDINGS: {e}")
        
        if findings:
            self.stats["end_findings_found"] += len(findings)
        
        return findings
    
    def extract_all_findings(
        self,
        resp: str,
        func_name: str,
        chain: List[str],
        vd: dict,
        project_root: Optional[Path] = None
    ) -> List[dict]:
        """
        応答からFINDINGSとEND_FINDINGSの両方を抽出
        
        Returns:
            すべての発見項目のリスト
        """
        all_findings = []
        
        # FINDINGS（中間）を抽出
        inline_findings = self.extract_inline_findings(
            resp, func_name, chain, vd, project_root
        )
        all_findings.extend(inline_findings)
        
        # END_FINDINGS（最終）を抽出
        end_findings = self.extract_end_findings(
            resp, func_name, chain, vd, project_root
        )
        all_findings.extend(end_findings)
        
        return all_findings
    
    def extract_taint_state(self, response: str) -> dict:
        """関数解析レスポンスからテイント状態を抽出"""
        try:
            first_line = response.strip().split('\n')[0]
            data = json.loads(first_line)
            return {
                "propagated_values": data.get("propagation", []),
                "applied_sanitizers": data.get("sanitizers", []),
                "reached_sinks": data.get("sinks", [])
            }
        except:
            return {}
    
    def extract_security_observations(self, response: str) -> List[dict]:
        """セキュリティ関連の観察事項を抽出"""
        observations = []
        
        # FINDINGSから抽出
        for pattern in [r'FINDINGS\s*=\s*({.*})', r'END_FINDINGS\s*=\s*({.*})']:
            findings_match = re.search(pattern, response)
            if findings_match:
                try:
                    findings = json.loads(findings_match.group(1))
                    for item in findings.get("items", []):
                        observations.append({
                            "type": item.get("rule"),
                            "observation": item.get("why"),
                            "location": f"{item.get('file')}:{item.get('line')}"
                        })
                except:
                    pass
        
        return observations
    
    def extract_risk_indicators(self, response: str) -> List[str]:
        """レスポンスからリスク指標を抽出"""
        risk_indicators = []
        
        # JSONからrule_matchesを取得
        try:
            first_line = response.strip().split('\n')[0]
            data = json.loads(first_line)
            rule_matches = data.get("rule_matches", [])
            if rule_matches:
                risk_indicators.extend([f"Matched rule: {rule}" for rule in rule_matches])
        except:
            pass
        
        # テキストから危険なパターンを検出
        dangerous_patterns = [
            (r"no\s+bounds?\s+check", "No bounds checking detected"),
            (r"no\s+validation", "No validation detected"),
            (r"untrusted\s+input", "Untrusted input detected"),
            (r"without\s+sanitization", "Missing sanitization"),
            (r"buffer\s+overflow", "Potential buffer overflow"),
            (r"memory\s+corruption", "Potential memory corruption"),
            (r"injection", "Potential injection vulnerability")
        ]
        
        for pattern, indicator in dangerous_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                risk_indicators.append(indicator)
        
        return list(set(risk_indicators))  # 重複を削除
    
    def parse_detailed_vuln_response(self, resp: str) -> dict:
        """LLMの脆弱性判定レスポンスから詳細情報を抽出"""
        lines = resp.strip().split('\n')
        
        # 1行目の判定結果
        vuln_decision = {}
        if lines:
            try:
                vuln_decision = json.loads(lines[0])
            except:
                pass
        
        # 2行目以降の詳細分析
        details = {}
        if len(lines) > 1:
            try:
                remaining_text = '\n'.join(lines[1:])
                
                # 複数のJSONブロックパターンに対応
                json_patterns = [
                    r'\{[\s\S]*"vulnerability_type"[\s\S]*\}',
                    r'\{[\s\S]*"severity"[\s\S]*\}',
                    r'\{[\s\S]*\}'
                ]
                
                for pattern in json_patterns:
                    json_match = re.search(pattern, remaining_text)
                    if json_match:
                        try:
                            details = json.loads(json_match.group(0))
                            break
                        except:
                            continue
                
                # JSONが見つからない場合は構造化解析
                if not details:
                    details = self._parse_structured_explanation(remaining_text)
                    
            except Exception as e:
                details = {"raw_explanation": '\n'.join(lines[1:]), "parse_error": str(e)}
        
        return {
            "decision": vuln_decision,
            "details": details,
            "full_response": resp
        }
    
    def _parse_structured_explanation(self, text: str) -> dict:
        """構造化されたテキスト説明から情報を抽出"""
        result = {
            "vulnerability_type": "Unknown",
            "severity": "Unknown",
            "description": text
        }
        
        # CWE番号の抽出
        cwe_match = re.search(r'CWE-(\d+)', text)
        if cwe_match:
            result["vulnerability_type"] = f"CWE-{cwe_match.group(1)}"
        
        # 重要度の抽出
        severity_match = re.search(r'(critical|high|medium|low)\s+severity', text, re.IGNORECASE)
        if severity_match:
            result["severity"] = severity_match.group(1).lower()
        
        # 攻撃シナリオの抽出
        if "attack" in text.lower() or "exploit" in text.lower():
            attack_section = re.search(r'(attack|exploit)[^.]*\.([^.]*\.){0,3}', text, re.IGNORECASE)
            if attack_section:
                result["attack_scenario"] = attack_section.group(0)
        
        return result
    
    def _validate_line_number(self, file_path: str, line_num: int, project_root: Optional[Path] = None) -> bool:
        """行番号が有効かチェック"""
        if line_num <= 0:
            return False
        
        try:
            if project_root and not Path(file_path).is_absolute():
                file_path = project_root / file_path
            
            if Path(file_path).exists():
                with open(file_path, 'r') as f:
                    total_lines = sum(1 for _ in f)
                    return 1 <= line_num <= total_lines
        except:
            pass
        
        return True
    
    def get_stats(self) -> dict:
        """統計情報を取得"""
        return self.stats.copy()