#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
脆弱性判定モジュール（改善版）
最終的な脆弱性判定と整合性チェックを担当
END_FINDINGSの抽出を強化し、フォールバック処理を追加
"""

from typing import Dict, List
from pathlib import Path
from ..prompts import get_end_prompt


class VulnerabilityAnalyzer:
    """最終的な脆弱性判定を担当するクラス（改善版）"""
    
    def __init__(
        self,
        code_extractor,
        vuln_parser,
        logger,
        conversation_manager,
        llm_handler,
        consistency_checker
    ):
        """
        Args:
            code_extractor: コード抽出器
            vuln_parser: 脆弱性パーサー
            logger: ロガー
            conversation_manager: 会話管理
            llm_handler: LLMハンドラー
            consistency_checker: 整合性チェッカー
        """
        self.code_extractor = code_extractor
        self.vuln_parser = vuln_parser
        self.logger = logger
        self.conversation_manager = conversation_manager
        self.llm_handler = llm_handler
        self.consistency_checker = consistency_checker
        
        # 統計情報
        self.stats = {
            "vulnerability_analyses": 0,
            "vulnerabilities_found": 0,
            "consistency_reevaluations": 0,
            "consistency_downgrades": 0,
            "findings_recovery_attempts": 0,
            "findings_recovery_successes": 0,
            "llm_retry_attempts": 0,
            "llm_retry_successes": 0,
            "false_positives_filtered": 0,
            "last_chance_attempts": 0
        }
    
    def perform_vulnerability_analysis(self, results: dict, chain: List[str], vd: dict) -> dict:
        """
        最終的な脆弱性判定とEND_FINDINGSの収集（改善版）
        
        Args:
            results: これまでの解析結果
            chain: 関数チェイン
            vd: 脆弱性詳細
            
        Returns:
            脆弱性判定結果
        """
        self.stats["vulnerability_analyses"] += 1
        
        # contextを先に定義（エラー修正の核心部分）
        context = {
            "phase": "vulnerability_analysis",
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown")
        }
        
        # 既存の脆弱性判定処理
        end_prompt = get_end_prompt()
        
        # 会話にプロンプトを追加
        self.conversation_manager.add_message("user", end_prompt)
        
        # ログ記録
        self.logger.log_section("Vulnerability Analysis", level=2)
        self.logger.writeln("### Prompt:")
        self.logger.writeln(end_prompt)
        self.logger.writeln("")
        
        # LLMに問い合わせ（contextは既に定義済み）
        vuln_response = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        self.logger.writeln("### Response:")
        self.logger.writeln(vuln_response)
        self.logger.writeln("")
        
        # 脆弱性判定をパース
        is_vuln, meta = self.vuln_parser.parse_vuln_response(vuln_response)
        vuln_details = self.vuln_parser.parse_detailed_vuln_response(vuln_response)
        
        if is_vuln:
            self.stats["vulnerabilities_found"] += 1
        
        # 【改善】END_FINDINGSを拡張抽出メソッドで処理
        self._extract_end_findings_enhanced(vuln_response, results, chain, vd, is_vuln)
        
        # 整合性チェック1: テイントフロー
        has_valid_taint_flow = self.consistency_checker.validate_taint_flow(results, chain, vd)
        
        if is_vuln and not has_valid_taint_flow:
            original_findings = results.get("inline_findings", []).copy()
            
            self.logger.writeln("[CONSISTENCY] No valid REE->sink path detected, triggering reevaluation")
            reevaluation = self._reevaluate_with_consistency(results, chain, vd)
            
            if reevaluation["reevaluated"]:
                is_vuln = reevaluation["is_vulnerable"]
                meta["reevaluated"] = True
                meta["reevaluation_reason"] = "no_taint_flow_path"
                vuln_response = reevaluation["reevaluation_response"]
                
                # 【修正】再評価後も必ずEND_FINDINGSを抽出
                new_findings_before = len(results.get("inline_findings", []))
                self._extract_end_findings_enhanced(vuln_response, results, chain, vd, is_vuln)
                new_findings_after = len(results.get("inline_findings", []))
                
                # もし新しいEND_FINDINGSが空で、元のFINDINGSがあった場合は復元
                if new_findings_after == new_findings_before and len(original_findings) > 0:
                    # 新しいEND_FINDINGSが追加されなかった場合、元のFINDINGSを保持
                    results["inline_findings"] = original_findings
                    self.logger.writeln(f"[INFO] Restored {len(original_findings)} original findings")
                
                self.stats["consistency_reevaluations"] += 1
        
        # 【改善】整合性チェック2: Findings一貫性（改善版）
        is_vuln = self._check_findings_consistency_enhanced(
            results, is_vuln, vuln_response, chain, vd, meta
        )

        # 最終結果の構築
        result = {
            "vulnerability": vuln_response,
            "vulnerability_details": vuln_details,
            "is_vulnerable": is_vuln,
            "meta": meta,
            "consistency_checks": {
                "taint_flow_valid": has_valid_taint_flow,
                "findings_consistent": not meta.get("downgraded", False)
            }
        }
        
        return result
    
    def _extract_end_findings_enhanced(self, vuln_response: str, results: dict, 
                                      chain: List[str], vd: dict, is_vuln: bool) -> None:
        """
        END_FINDINGSを抽出して結果に追加（改善版）
        【改善点4】END_FINDINGSが0件の場合、全種類を再抽出
        【改善点5】それでも0件なら、具体的な指示で再要求
        """
        try:
            func_name = chain[-1] if chain else "unknown"
            current_func_info = None
            if func_name in self.code_extractor.user_functions:
                current_func_info = self.code_extractor.user_functions[func_name]
            
            extended_vd = vd.copy()
            if current_func_info:
                extended_vd['current_file'] = current_func_info['file']
                extended_vd['current_line'] = current_func_info['line']
            
            # まず通常のEND_FINDINGS抽出
            end_findings = self.vuln_parser.extract_end_findings(
                vuln_response, func_name, chain, extended_vd,
                self.code_extractor.project_root
            )
            
            # END_FINDINGSが0件で、脆弱性ありの場合
            if not end_findings and is_vuln:
                self.stats["findings_recovery_attempts"] += 1
                self.logger.writeln("[INFO] No END_FINDINGS found, attempting flexible extraction")
                
                # 柔軟な抽出を試みる（extract_all_findings_flexibleが利用可能な場合）
                if hasattr(self.vuln_parser, 'extract_all_findings_flexible'):
                    fallback_findings = self.vuln_parser.extract_all_findings_flexible(
                        vuln_response, func_name, chain, extended_vd,
                        self.code_extractor.project_root
                    )
                else:
                    # フォールバック: 通常のextract_all_findingsを使用
                    fallback_findings = self.vuln_parser.extract_all_findings(
                        vuln_response, func_name, chain, extended_vd,
                        self.code_extractor.project_root
                    )
                
                if fallback_findings:
                    end_findings = fallback_findings
                    self.stats["findings_recovery_successes"] += 1
                    self.logger.writeln(f"[INFO] Recovered {len(end_findings)} findings via flexible extraction")
                
                # それでも0件なら、LLMに具体的に再要求
                elif is_vuln:
                    self.stats["llm_retry_attempts"] += 1
                    self.logger.writeln("[INFO] Requesting concrete END_FINDINGS from LLM")
                    
                    retry_prompt = self._build_findings_retry_prompt(extended_vd, func_name, vd)
                    self.conversation_manager.add_message("user", retry_prompt)
                    
                    context = {
                        "phase": "findings_retry",
                        "chain": " -> ".join(chain),
                        "sink": vd.get("sink", "unknown")
                    }
                    
                    retry_resp = self.llm_handler.ask_with_handler(context, self.conversation_manager)
                    
                    if retry_resp:
                        retry_findings = self.vuln_parser.extract_end_findings(
                            retry_resp, func_name, chain, extended_vd,
                            self.code_extractor.project_root
                        )
                        
                        if retry_findings:
                            end_findings = retry_findings
                            self.stats["llm_retry_successes"] += 1
                            self.logger.writeln(f"[INFO] Retrieved {len(retry_findings)} findings after LLM retry")
            
            if end_findings:
                results["inline_findings"].extend(end_findings)
                self.logger.writeln(f"[INFO] Total END_FINDINGS extracted: {len(end_findings)}")
                
        except Exception as e:
            self.logger.writeln(f"[ERROR] END_FINDINGS extraction failed: {e}")
    
    def _check_findings_consistency_enhanced(self, results: dict, is_vuln: bool,
                                            vuln_response: str,
                                            chain: List[str], vd: dict, meta: dict) -> bool:
        """整合性チェック（Findings一貫性）- 改善版"""
        
        # 1. まず現在のfindingsから誤検出を除外
        original_findings = results.get("inline_findings", [])
        pre_filtered_findings = []
        false_positive_count = 0
        
        for f in original_findings:
            if not self.consistency_checker._is_likely_false_positive(f):
                pre_filtered_findings.append(f)
            else:
                false_positive_count += 1
                self.logger.writeln(f"[DEBUG] Detected likely false positive: {f}")
        
        if false_positive_count > 0:
            self.logger.writeln(f"[INFO] Filtered out {false_positive_count} false positives")
            self.stats["false_positives_filtered"] = self.stats.get("false_positives_filtered", 0) + false_positive_count
        
        # 2. ConsistencyCheckerで整合性チェック（フィルタ済みfindingsで）
        adj_is_vuln, adj_findings, reason = self.consistency_checker.check_findings_consistency(
            vuln_found=is_vuln,
            findings=pre_filtered_findings,  # フィルタ済みを渡す
            response=vuln_response,
            metadata={"chain": " -> ".join(chain), "sink": vd.get("sink")}
        )
        
        # 3. ConsistencyCheckerの提案に従って更新
        if adj_findings != pre_filtered_findings:
            # 救済抽出などで新しいfindingsが追加された可能性
            results["inline_findings"] = adj_findings
            self.logger.writeln(f"[INFO] Findings adjusted by ConsistencyChecker: "
                            f"{len(pre_filtered_findings)} -> {len(adj_findings)}")
        else:
            # 変更なければフィルタ済みを使用
            results["inline_findings"] = pre_filtered_findings
        
        # 4. 脆弱性フラグの調整
        if adj_is_vuln != is_vuln:
            self.logger.writeln(f"[CONSISTENCY] Adjusting vulnerability flag: "
                            f"{is_vuln} -> {adj_is_vuln} ({reason})")
            is_vuln = adj_is_vuln
            meta["consistency_reason"] = reason
            
            # ダウングレードされた場合の統計
            if is_vuln and not adj_is_vuln:
                meta["downgraded"] = True
                self.stats["consistency_downgrades"] += 1
        
        # 5. 最終確認：有効なfindingsがあるのに脆弱性なしの場合
        if not is_vuln and results.get("inline_findings"):
            valid_findings = self._get_valid_findings(results["inline_findings"])
            if valid_findings:
                self.logger.writeln(f"[WARN] Inconsistency detected: "
                                f"{len(valid_findings)} valid findings but vulnerability_found=no")
                # 最後のチャンスプロンプトを試みる
                if not meta.get("last_chance_attempted"):
                    meta["last_chance_attempted"] = True
                    self._attempt_last_chance_findings(chain, vd, results)
        
        return is_vuln
    
    def _attempt_last_chance_findings(self, chain: List[str], vd: dict, results: dict) -> None:
        """最後のチャンスでfindingsを取得"""
        self.stats["last_chance_attempts"] += 1
        func_name = chain[-1] if chain else "unknown"
        
        prompt = self._build_last_chance_prompt(vd, func_name)
        self.conversation_manager.add_message("user", prompt)
        
        context = {
            "phase": "last_chance_findings",
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown")
        }
        
        response = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        if response:
            # 拡張vdを構築
            extended_vd = vd.copy()
            if func_name in self.code_extractor.user_functions:
                func_info = self.code_extractor.user_functions[func_name]
                extended_vd['current_file'] = func_info['file']
                extended_vd['current_line'] = func_info['line']
            
            findings = self.vuln_parser.extract_end_findings(
                response, func_name, chain, extended_vd,
                self.code_extractor.project_root
            )
            
            if findings:
                results["inline_findings"].extend(findings)
                self.logger.writeln(f"[INFO] Last chance succeeded: {len(findings)} findings added")
    
    def _get_valid_findings(self, findings: List[dict]) -> List[dict]:
        """
        有効なfindingsを取得
        fileとlineが適切に設定されているものを選別
        """
        valid_findings = []
        
        for f in findings:
            # プレースホルダーでない実際のファイル名を持つfindingを有効とする
            file_path = f.get("file", "")
            line_num = f.get("line", 0)
            
            # プレースホルダーのパターン
            placeholders = ["unknown", "<path>", "n/a", "???", "undefined", "<file>", "null", "none"]
            
            is_valid_file = (
                file_path and 
                not any(p in file_path.lower() for p in placeholders) and
                not (file_path.startswith("<") and file_path.endswith(">"))
            )
            
            is_valid_line = line_num > 0
            
            if is_valid_file and is_valid_line:
                valid_findings.append(f)
            # ✅ 修正: debugプロパティのチェックを削除またはhasattrを使用
            elif hasattr(self.logger, 'debug') and self.logger.debug:
                self.logger.writeln(f"[DEBUG] Invalid finding: file='{file_path}', line={line_num}")
        
        return valid_findings
    
    def _build_findings_retry_prompt(self, extended_vd: dict, func_name: str, vd: dict) -> str:
        """Findings再要求用のプロンプトを構築"""
        actual_file = extended_vd.get('current_file') or extended_vd.get('file', 'unknown')
        actual_line = extended_vd.get('current_line') or extended_vd.get('line', 1)
        
        return f"""You identified a vulnerability but didn't provide concrete END_FINDINGS.
Please provide END_FINDINGS for the vulnerability in the following format:

END_FINDINGS={{"items":[{{
    "file": "{actual_file}",
    "line": {actual_line},
    "function": "{func_name}",
    "sink_function": "{vd.get('sink', 'unknown')}",
    "rule": "vulnerability_type",
    "why": "Specific explanation of why this is vulnerable",
    "phase": "end"
}}]}}

Use the actual file path and line number from the vulnerability destination.
If the exact location is unknown, use:
- file: "{actual_file}"
- line: {actual_line}"""
    
    def _build_last_chance_prompt(self, vd: dict, func_name: str) -> str:
        """最後のチャンス用プロンプトを構築"""
        return f"""You identified a vulnerability but no concrete findings were provided.
This is the last chance to provide findings before the vulnerability is rejected.

Please provide at least one END_FINDINGS entry with:
- file: {vd.get('file', 'the affected file')}
- line: {vd.get('line', 'the line number')}
- function: {func_name}
- sink_function: {vd.get('sink', 'unknown')}
- why: specific reason for the vulnerability

Format: END_FINDINGS={{"items":[{{"file":"...", "line":..., "function":"...", "sink_function":"...", "why":"..."}}]}}""" 
    
    
    def _reevaluate_with_consistency(self, results: dict, chain: List[str], vd: dict) -> dict:
        """整合性チェックに基づく再評価"""
        reevaluation_prompt = """Based on the taint analysis, reconsider the vulnerability assessment:

IMPORTANT: A vulnerability exists ONLY if:
1. Data from REE (untrusted source) actually flows to a dangerous sink
2. The data flow is explicit and traceable through the code
3. There are insufficient sanitizers or bounds checks

Review the analysis and provide a corrected assessment.
Was there an ACTUAL data flow from REE inputs to the sink? Answer with the standard two-line format."""

        # 会話に再評価プロンプトを追加
        self.conversation_manager.add_message("user", reevaluation_prompt)
        
        # LLMに問い合わせ
        context = {
            "phase": "consistency_reevaluation",
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown")
        }
        
        response = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        # ログ記録
        self.logger.writeln("\n[REEVALUATION] Consistency check triggered")
        self.logger.writeln(response)
        
        # 再評価結果をパース
        is_vuln, meta = self.vuln_parser.parse_vuln_response(response)
        
        return {
            "reevaluated": True,
            "is_vulnerable": is_vuln,
            "reevaluation_response": response,
            "meta": meta
        }
    
    def get_stats(self) -> Dict:
        """統計情報を取得"""
        return self.stats.copy()