#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
脆弱性判定モジュール（統合パーサー対応版）
最終的な脆弱性判定と整合性チェックを担当
"""

from typing import Dict, List
from pathlib import Path
from ..prompts.prompts import get_end_prompt
from ..extraction.unified_parser import UnifiedLLMResponseParser
from ..extraction.vulnerability_utils import VulnerabilityUtils
from ..processing.response_validator import SmartResponseValidator


class VulnerabilityAnalyzer:
    """最終的な脆弱性判定を担当するクラス"""
    
    def __init__(
        self,
        code_extractor,
        vuln_parser,  # 後方互換性のため残す
        logger,
        conversation_manager,
        llm_handler,
        consistency_checker
    ):
        self.code_extractor = code_extractor
        self.logger = logger
        self.conversation_manager = conversation_manager
        self.llm_handler = llm_handler
        self.consistency_checker = consistency_checker
        
        # 新しい統合パーサーとユーティリティ
        self.parser = UnifiedLLMResponseParser(
            project_root=code_extractor.project_root,
            debug=getattr(logger, 'debug_mode', False)
        )
        self.vuln_utils = VulnerabilityUtils(
            debug=getattr(logger, 'debug_mode', False)
        )
        self.validator = SmartResponseValidator(
            debug=getattr(logger, 'debug_mode', False)
        )
        
        # 後方互換性のためvuln_parserも保持
        self.vuln_parser = vuln_parser
        
        # 統計情報
        self.stats = {
            "vulnerability_analyses": 0,
            "vulnerabilities_found": 0,
            "consistency_reevaluations": 0,
            "consistency_downgrades": 0,
            "findings_recovery_attempts": 0,
            "findings_recovery_successes": 0,
            "false_positives_filtered": 0,
            "parse_successes": 0,
            "parse_failures": 0
        }
    
    def perform_vulnerability_analysis(self, results: dict, chain: List[str], vd: dict) -> dict:
        """最終的な脆弱性判定とEND_FINDINGSの収集（統合パーサー使用）"""
        self.stats["vulnerability_analyses"] += 1
        
        # contextを定義
        context = {
            "phase": "end",  # endフェーズ
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown")
        }
        
        # 脆弱性判定プロンプト
        end_prompt = get_end_prompt()
        
        # 会話にプロンプトを追加
        self.conversation_manager.add_message("user", end_prompt)
        
        # ログ記録
        self.logger.log_section("Vulnerability Analysis", level=2)
        self.logger.writeln("### Prompt:")
        self.logger.writeln(end_prompt)
        self.logger.writeln("")
        
        # LLMに問い合わせ
        vuln_response = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        self.logger.writeln("### Response:")
        self.logger.writeln(vuln_response)
        self.logger.writeln("")
        
        # 早期検証と自動修復
        is_valid, recovered = self.validator.validate_and_recover(vuln_response, "end")
        
        if not is_valid:
            self.logger.writeln("[WARN] Initial validation failed for vulnerability analysis")
        
        # 統合パーサーで解析
        parsed = self.parser.parse_complete_response(recovered, "end", context)
        
        if parsed.get("parse_success"):
            self.stats["parse_successes"] += 1
        else:
            self.stats["parse_failures"] += 1
            self.logger.writeln("[WARN] Failed to parse vulnerability response completely")
        
        # 脆弱性判定を取得
        vuln_decision = parsed.get("vulnerability_decision", {})
        is_vuln = vuln_decision.get("found", False)
        vuln_details = parsed.get("vulnerability_details", {})
        
        # メタデータ
        meta = {
            "parse_success": parsed.get("parse_success", False),
            "raw_decision": vuln_decision.get("raw", {})
        }
        
        if is_vuln:
            self.stats["vulnerabilities_found"] += 1
        
        # END_FINDINGSを抽出（統合パーサーから直接取得）
        end_findings = parsed.get("end_findings", [])
        self._process_end_findings(end_findings, results, chain, vd, is_vuln)
        
        # 通常のFINDINGSも確認（念のため）
        regular_findings = parsed.get("findings", [])
        if regular_findings and not end_findings:
            self.logger.writeln(f"[INFO] Using regular findings as END_FINDINGS: {len(regular_findings)} items")
            self._process_end_findings(regular_findings, results, chain, vd, is_vuln)
        
        # 整合性チェック1: テイントフロー
        has_valid_taint_flow = self.consistency_checker.validate_taint_flow(results, chain, vd)
        
        if is_vuln and not has_valid_taint_flow:
            original_findings = results.get("inline_findings", []).copy()
            
            self.logger.writeln("[CONSISTENCY] No valid REE->sink path detected, triggering reevaluation")
            reevaluation = self._reevaluate_with_consistency(results, chain, vd)
            
            if reevaluation["reevaluated"]:
                is_vuln = reevaluation["is_vulnerable"]
                meta["reevaluated"] = True
                meta["reevaluation_reason"] = "no_taint_flow_path"
                vuln_response = reevaluation["reevaluation_response"]
                
                # 再評価後もEND_FINDINGSを抽出
                re_parsed = self.parser.parse_complete_response(
                    reevaluation["reevaluation_response"], "end", context
                )
                re_end_findings = re_parsed.get("end_findings", [])
                
                if re_end_findings:
                    self._process_end_findings(re_end_findings, results, chain, vd, is_vuln)
                elif len(original_findings) > 0:
                    # 新しいEND_FINDINGSが空で、元のFINDINGSがあった場合は復元
                    results["inline_findings"] = original_findings
                    self.logger.writeln(f"[INFO] Restored {len(original_findings)} original findings")
                
                self.stats["consistency_reevaluations"] += 1
        
        # 整合性チェック2: Findings一貫性
        is_vuln = self._check_findings_consistency_enhanced(
            results, is_vuln, parsed, chain, vd, meta
        )
        
        # 最終結果の構築
        result = {
            "vulnerability": vuln_response,
            "vulnerability_details": vuln_details,
            "is_vulnerable": is_vuln,
            "meta": meta,
            "parsed_data": {
                "decision": vuln_decision,
                "details": vuln_details,
                "end_findings": end_findings
            },
            "consistency_checks": {
                "taint_flow_valid": has_valid_taint_flow,
                "findings_consistent": not meta.get("downgraded", False)
            }
        }
        
        return result
    
    def _process_end_findings(self, end_findings: List[Dict], results: Dict, 
                             chain: List[str], vd: Dict, is_vuln: bool) -> None:
        """END_FINDINGSを処理して結果に追加"""
        if not end_findings and is_vuln:
            # 脆弱性ありなのにEND_FINDINGSが0件の場合
            self.stats["findings_recovery_attempts"] += 1
            self.logger.writeln("[INFO] No END_FINDINGS found for vulnerability, attempting recovery")
            
            # LLMに再要求
            end_findings = self._request_concrete_findings(chain, vd)
            
            if end_findings:
                self.stats["findings_recovery_successes"] += 1
        
        if end_findings:
            # phaseをendに設定
            for finding in end_findings:
                finding["phase"] = "end"
            
            results["inline_findings"].extend(end_findings)
            self.logger.writeln(f"[INFO] Total END_FINDINGS extracted: {len(end_findings)}")
    
    def _request_concrete_findings(self, chain: List[str], vd: dict) -> List[dict]:
        """LLMに具体的なfindingsを要求"""
        func_name = chain[-1] if chain else "unknown"
        
        retry_prompt = f"""You identified a vulnerability but didn't provide concrete END_FINDINGS.
Please provide END_FINDINGS for the vulnerability in the following format:

END_FINDINGS={{"items":[{{
    "file": "{vd.get('file', 'unknown')}",
    "line": {vd.get('line', 1)},
    "function": "{func_name}",
    "sink_function": "{vd.get('sink', 'unknown')}",
    "rule": "vulnerability_type",
    "why": "Specific explanation",
    "phase": "end"
}}]}}"""
        
        self.conversation_manager.add_message("user", retry_prompt)
        
        context = {
            "phase": "end",
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown"),
            "retry_type": "findings_recovery"
        }
        
        retry_resp = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        if retry_resp:
            # 統合パーサーで解析
            parsed = self.parser.parse_complete_response(retry_resp, "end", context)
            return parsed.get("end_findings", [])
        
        return []
    
    def _check_findings_consistency_enhanced(self, results: Dict, is_vuln: bool,
                                            parsed: Dict,
                                            chain: List[str], vd: Dict, meta: Dict) -> bool:
        """整合性チェック（Findings一貫性）"""
        
        # 誤検出を除外
        original_findings = results.get("inline_findings", [])
        pre_filtered_findings = []
        false_positive_count = 0
        
        for f in original_findings:
            if not self.consistency_checker._is_likely_false_positive(f):
                pre_filtered_findings.append(f)
            else:
                false_positive_count += 1
                self.logger.writeln(f"[DEBUG] Detected likely false positive: {f}")
        
        if false_positive_count > 0:
            self.logger.writeln(f"[INFO] Filtered out {false_positive_count} false positives")
            self.stats["false_positives_filtered"] += false_positive_count
        
        # レスポンス全体を渡す（救済抽出のため）
        vuln_response = parsed.get("raw_response", "")
        
        # ConsistencyCheckerで整合性チェック
        adj_is_vuln, adj_findings, reason = self.consistency_checker.check_findings_consistency(
            vuln_found=is_vuln,
            findings=pre_filtered_findings,
            response=vuln_response,
            metadata={"chain": " -> ".join(chain), "sink": vd.get("sink")}
        )
        
        # ConsistencyCheckerの提案に従って更新
        results["inline_findings"] = adj_findings
        
        # 脆弱性フラグの調整
        if adj_is_vuln != is_vuln:
            self.logger.writeln(f"[CONSISTENCY] Adjusting vulnerability flag: "
                              f"{is_vuln} -> {adj_is_vuln} ({reason})")
            is_vuln = adj_is_vuln
            meta["consistency_reason"] = reason
            
            if is_vuln and not adj_is_vuln:
                meta["downgraded"] = True
                self.stats["consistency_downgrades"] += 1
        
        return is_vuln
    
    def _reevaluate_with_consistency(self, results: Dict, chain: List[str], vd: Dict) -> Dict:
        """整合性チェックに基づく再評価"""
        reevaluation_prompt = """Based on the taint analysis, reconsider the vulnerability assessment:

IMPORTANT: A vulnerability exists ONLY if:
1. Data from REE (untrusted source) actually flows to a dangerous sink
2. The data flow is explicit and traceable through the code
3. There are insufficient sanitizers or bounds checks

Review the analysis and provide a corrected assessment.
Was there an ACTUAL data flow from REE inputs to the sink? Answer with the standard format:

Line 1: {"vulnerability_found":"yes" or "no"}
Line 2: {detailed JSON}
Line 3: END_FINDINGS={"items":[...]}"""

        self.conversation_manager.add_message("user", reevaluation_prompt)
        
        context = {
            "phase": "end",
            "chain": " -> ".join(chain),
            "sink": vd.get("sink", "unknown"),
            "reevaluation": True
        }
        
        response = self.llm_handler.ask_with_handler(context, self.conversation_manager)
        
        self.logger.writeln("\n[REEVALUATION] Consistency check triggered")
        self.logger.writeln(response)
        
        # 統合パーサーで解析
        parsed = self.parser.parse_complete_response(response, "end", context)
        vuln_decision = parsed.get("vulnerability_decision", {})
        is_vuln = vuln_decision.get("found", False)
        
        return {
            "reevaluated": True,
            "is_vulnerable": is_vuln,
            "reevaluation_response": response,
            "meta": vuln_decision.get("raw", {})
        }
    
    def get_stats(self) -> Dict:
        """統計情報を取得"""
        stats = self.stats.copy()
        
        # パーサーの統計を追加
        stats["parser_stats"] = self.parser.get_stats()
        
        # バリデーターの統計を追加
        stats["validator_stats"] = self.validator.get_stats()
        
        # ユーティリティの統計を追加  
        stats["utils_stats"] = self.vuln_utils.get_stats()
        
        return stats